{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Vader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset I chose is of movie reviews who have already been labelled as either having positive or negative sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#First must import libraries needed to perform analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe \n",
    "df = pd.read_csv('Desktop\\Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I always wrote this series off as being a comp...      0\n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
       "2  This movie was so poorly written and directed ...      0\n",
       "3  The most interesting thing about Miryang (Secr...      1\n",
       "4  when i first read about \"berlin am meer\" i did...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick glance at how our data looks now\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Seeing how the distribution of negative and positive sentiments initially looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2505\n",
       "0    2495\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here I will apply the polarity_scores function of our analyzer to our text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column that will show the performance of our analyzer on the text\n",
    "df['polarity_score'] = df['text'].apply(lambda text: analyzer.polarity_scores(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.039, 'neu': 0.813, 'pos': 0.148, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.086, 'neu': 0.836, 'pos': 0.078, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.184, 'neu': 0.685, 'pos': 0.131, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.151, 'neu': 0.766, 'pos': 0.083, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.128, 'neu': 0.762, 'pos': 0.11, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I always wrote this series off as being a comp...      0   \n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0   \n",
       "2  This movie was so poorly written and directed ...      0   \n",
       "3  The most interesting thing about Miryang (Secr...      1   \n",
       "4  when i first read about \"berlin am meer\" i did...      0   \n",
       "\n",
       "                                      polarity_score  \n",
       "0  {'neg': 0.039, 'neu': 0.813, 'pos': 0.148, 'co...  \n",
       "1  {'neg': 0.086, 'neu': 0.836, 'pos': 0.078, 'co...  \n",
       "2  {'neg': 0.184, 'neu': 0.685, 'pos': 0.131, 'co...  \n",
       "3  {'neg': 0.151, 'neu': 0.766, 'pos': 0.083, 'co...  \n",
       "4  {'neg': 0.128, 'neu': 0.762, 'pos': 0.11, 'com...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column that will only focus on the compound element\n",
    "df['compound'] = df['polarity_score'].apply(lambda score: score['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.039, 'neu': 0.813, 'pos': 0.148, 'co...</td>\n",
       "      <td>0.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.086, 'neu': 0.836, 'pos': 0.078, 'co...</td>\n",
       "      <td>-0.1618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.184, 'neu': 0.685, 'pos': 0.131, 'co...</td>\n",
       "      <td>-0.9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.151, 'neu': 0.766, 'pos': 0.083, 'co...</td>\n",
       "      <td>-0.9962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.128, 'neu': 0.762, 'pos': 0.11, 'com...</td>\n",
       "      <td>-0.6673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I always wrote this series off as being a comp...      0   \n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0   \n",
       "2  This movie was so poorly written and directed ...      0   \n",
       "3  The most interesting thing about Miryang (Secr...      1   \n",
       "4  when i first read about \"berlin am meer\" i did...      0   \n",
       "\n",
       "                                      polarity_score  compound  \n",
       "0  {'neg': 0.039, 'neu': 0.813, 'pos': 0.148, 'co...    0.9934  \n",
       "1  {'neg': 0.086, 'neu': 0.836, 'pos': 0.078, 'co...   -0.1618  \n",
       "2  {'neg': 0.184, 'neu': 0.685, 'pos': 0.131, 'co...   -0.9683  \n",
       "3  {'neg': 0.151, 'neu': 0.766, 'pos': 0.083, 'co...   -0.9962  \n",
       "4  {'neg': 0.128, 'neu': 0.762, 'pos': 0.11, 'com...   -0.6673  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a second label column that will demonstrate what label our analyzer would give these reviews\n",
    "df['analyzer_label'] = df['compound'].apply(lambda compound: 'pos' if compound >= 0 else 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>compound</th>\n",
       "      <th>analyzer_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.039, 'neu': 0.813, 'pos': 0.148, 'co...</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.086, 'neu': 0.836, 'pos': 0.078, 'co...</td>\n",
       "      <td>-0.1618</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.184, 'neu': 0.685, 'pos': 0.131, 'co...</td>\n",
       "      <td>-0.9683</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.151, 'neu': 0.766, 'pos': 0.083, 'co...</td>\n",
       "      <td>-0.9962</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.128, 'neu': 0.762, 'pos': 0.11, 'com...</td>\n",
       "      <td>-0.6673</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I always wrote this series off as being a comp...      0   \n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0   \n",
       "2  This movie was so poorly written and directed ...      0   \n",
       "3  The most interesting thing about Miryang (Secr...      1   \n",
       "4  when i first read about \"berlin am meer\" i did...      0   \n",
       "\n",
       "                                      polarity_score  compound analyzer_label  \n",
       "0  {'neg': 0.039, 'neu': 0.813, 'pos': 0.148, 'co...    0.9934            pos  \n",
       "1  {'neg': 0.086, 'neu': 0.836, 'pos': 0.078, 'co...   -0.1618            neg  \n",
       "2  {'neg': 0.184, 'neu': 0.685, 'pos': 0.131, 'co...   -0.9683            neg  \n",
       "3  {'neg': 0.151, 'neu': 0.766, 'pos': 0.083, 'co...   -0.9962            neg  \n",
       "4  {'neg': 0.128, 'neu': 0.762, 'pos': 0.11, 'com...   -0.6673            neg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    2505\n",
       "neg    2495\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have obtained columns for both the initial labels as well as how our sentiment analyzer labelled them.\n",
    "#let's compare the distribution now between the two\n",
    "df['label'] = df['label'].replace(1, 'pos')\n",
    "df['label'] = df['label'].replace(0, 'neg')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    3257\n",
       "neg    1743\n",
       "Name: analyzer_label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['analyzer_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sklearn to analyze the performance of our analyzer on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1351 1144]\n",
      " [ 392 2113]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6928"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(df['label'], df['analyzer_label'])\n",
    "print(cm)\n",
    "accuracy_score(df['label'], df['analyzer_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We observe that the analyzer performed with an accuracy rate of 70%. \n",
    "### Now we will analyze another dataset using an SVM classifier model to perform sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe in which we look at tweets of user complaints of airlines\n",
    "df2 = pd.read_csv('Desktop\\Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        14640\n",
       "airline_sentiment               14640\n",
       "airline_sentiment_confidence    14640\n",
       "negativereason                   9178\n",
       "negativereason_confidence       10522\n",
       "airline                         14640\n",
       "airline_sentiment_gold             40\n",
       "name                            14640\n",
       "negativereason_gold                32\n",
       "retweet_count                   14640\n",
       "text                            14640\n",
       "tweet_coord                      1019\n",
       "tweet_created                   14640\n",
       "tweet_location                   9907\n",
       "user_timezone                    9820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]                      164\n",
       "[40.64656067, -73.78334045]       6\n",
       "[32.91792297, -97.00367737]       3\n",
       "[40.64646912, -73.79133606]       3\n",
       "[40.68994668, -73.91637642]       2\n",
       "[33.75348859, -116.36209633]      2\n",
       "[39.1766101, -76.6700606]         2\n",
       "[37.99311597, -84.52114659]       2\n",
       "[37.78618135, -122.45742542]      2\n",
       "[32.82813261, -97.25115941]       2\n",
       "[35.22643463, -80.93879965]       2\n",
       "[40.69017276, -73.91646118]       2\n",
       "[39.83426941, -104.69960636]      2\n",
       "[18.22245647, -63.00369733]       2\n",
       "[34.0213466, -118.45229268]       2\n",
       "[37.62006843, -122.38822083]      2\n",
       "[33.75539049, -116.36196163]      2\n",
       "[40.68996177, -73.91640136]       2\n",
       "[40.69002464, -73.91638072]       2\n",
       "[25.7789761, -80.1353923]         1\n",
       "[40.77265898, -73.86525922]       1\n",
       "[39.91370182, -75.3405344]        1\n",
       "[47.62581201, -122.3501506]       1\n",
       "[33.7008468, -118.0192094]        1\n",
       "[39.1765188, -76.6696894]         1\n",
       "[40.46692522, -82.64567078]       1\n",
       "[40.64779984, -73.78283404]       1\n",
       "[33.05776114, -96.78169517]       1\n",
       "[34.0219817, -118.38591198]       1\n",
       "[36.08576903, -115.14953095]      1\n",
       "                               ... \n",
       "[39.85861725, -104.67232956]      1\n",
       "[39.8749922, -75.24017448]        1\n",
       "[18.47233225, -68.39941165]       1\n",
       "[37.61833841, -122.38389799]      1\n",
       "[33.81346953, -117.91426571]      1\n",
       "[34.02153389, -118.45231518]      1\n",
       "[34.10909961, -118.32361693]      1\n",
       "[40.51794328, -74.48516831]       1\n",
       "[27.97575376, -82.53714356]       1\n",
       "[40.85036847, -74.42575912]       1\n",
       "[22.31355693, 113.92636768]       1\n",
       "[40.78986648, -73.10068286]       1\n",
       "[40.63767372, -74.11075451]       1\n",
       "[37.40321679, -121.96988433]      1\n",
       "[29.81532281, -95.40830048]       1\n",
       "[41.78546237, -87.7430551]        1\n",
       "[33.2145038, -96.9321504]         1\n",
       "[40.2376266, -74.9171435]         1\n",
       "[37.61907, -122.38607]            1\n",
       "[41.79410567, -87.74243312]       1\n",
       "[30.441566, -84.281745]           1\n",
       "[35.22604872, -80.93863381]       1\n",
       "[43.60417384, -110.7362561]       1\n",
       "[37.61829369, -122.39192247]      1\n",
       "[33.4338494, -111.9963312]        1\n",
       "[59.38247253, 18.00789007]        1\n",
       "[-38.0271635, 145.2112317]        1\n",
       "[41.92992293, -87.66944213]       1\n",
       "[26.37067479, -80.10215823]       1\n",
       "[41.06865736, -73.70398273]       1\n",
       "Name: tweet_coord, Length: 832, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['airline_sentiment_gold'].value_counts()\n",
    "df2['negativereason_gold'].value_counts()\n",
    "df2['tweet_coord'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since airline sentiment gold, negative reason gold and tweet cord have barely any real values, we will delete them\n",
    "df2 = df2.drop(columns = ['airline_sentiment_gold', 'negativereason_gold', 'tweet_coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline        name  \\\n",
       "0            NaN                        NaN  Virgin America     cairdin   \n",
       "1            NaN                     0.0000  Virgin America    jnardino   \n",
       "2            NaN                        NaN  Virgin America  yvonnalynn   \n",
       "3     Bad Flight                     0.7033  Virgin America    jnardino   \n",
       "4     Can't Tell                     1.0000  Virgin America    jnardino   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                @VirginAmerica What @dhepburn said.   \n",
       "1              0  @VirginAmerica plus you've added commercials t...   \n",
       "2              0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3              0  @VirginAmerica it's really aggressive to blast...   \n",
       "4              0  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24863b70978>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now let's see how many neutral, negative and positive labels there are overall\n",
    "df2['airline_sentiment'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because we are only focusing on sentiment analysis, I only want to focus on the text features\n",
    "#Our X value will be the text features, and the y will be the labels of neutral, negative or positive\n",
    "X = df2.iloc[:, 8]\n",
    "y = df2.iloc[: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 1777, stop_words = stopwords.words('english'), max_df = .7, min_df = 10 )\n",
    "X = vectorizer.fit_transform(X).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will split the dataset into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6377     negative\n",
      "4597     positive\n",
      "3839     positive\n",
      "5518     negative\n",
      "3210     negative\n",
      "1534     negative\n",
      "7344     negative\n",
      "8271     positive\n",
      "728      negative\n",
      "5606     positive\n",
      "6536     negative\n",
      "7218      neutral\n",
      "11088    positive\n",
      "6116     negative\n",
      "10470    negative\n",
      "11689    negative\n",
      "13929    negative\n",
      "7115     negative\n",
      "7079     negative\n",
      "13024    negative\n",
      "11246    negative\n",
      "6210      neutral\n",
      "10777    negative\n",
      "841      negative\n",
      "2995     positive\n",
      "3948      neutral\n",
      "8376     negative\n",
      "779      negative\n",
      "5804     positive\n",
      "12784    positive\n",
      "           ...   \n",
      "7877     positive\n",
      "4851     negative\n",
      "5072     negative\n",
      "2163     negative\n",
      "6036     negative\n",
      "6921     negative\n",
      "6216      neutral\n",
      "11085    negative\n",
      "537      negative\n",
      "9893     negative\n",
      "2897     negative\n",
      "7768     negative\n",
      "2222      neutral\n",
      "10327    negative\n",
      "2599     negative\n",
      "705       neutral\n",
      "3468     negative\n",
      "6744     negative\n",
      "14116    negative\n",
      "5874     positive\n",
      "4373     negative\n",
      "7891      neutral\n",
      "9225     negative\n",
      "14019    negative\n",
      "4859     positive\n",
      "13123     neutral\n",
      "3264     positive\n",
      "9845     negative\n",
      "10799    negative\n",
      "2732     negative\n",
      "Name: airline_sentiment, Length: 10980, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13983    negative\n",
      "14484    negative\n",
      "6403     negative\n",
      "9653     negative\n",
      "13268    negative\n",
      "2384      neutral\n",
      "9613     negative\n",
      "11612    negative\n",
      "9252     negative\n",
      "13923    negative\n",
      "577       neutral\n",
      "9298     negative\n",
      "6236      neutral\n",
      "12155    negative\n",
      "6277     negative\n",
      "9332     negative\n",
      "578      positive\n",
      "8780      neutral\n",
      "4055     negative\n",
      "7302     negative\n",
      "5023     positive\n",
      "1856      neutral\n",
      "13193    negative\n",
      "14012    negative\n",
      "10020    negative\n",
      "8124     negative\n",
      "12550    negative\n",
      "9571     negative\n",
      "6978      neutral\n",
      "3569      neutral\n",
      "           ...   \n",
      "9135     negative\n",
      "6145     positive\n",
      "6600     negative\n",
      "8134     positive\n",
      "8368     negative\n",
      "10793     neutral\n",
      "10326    negative\n",
      "6139     positive\n",
      "893      positive\n",
      "12146    negative\n",
      "13883    negative\n",
      "11822    negative\n",
      "4341     positive\n",
      "11260    negative\n",
      "2524     negative\n",
      "6201     positive\n",
      "10258    negative\n",
      "13261    negative\n",
      "7423      neutral\n",
      "2923     negative\n",
      "4894      neutral\n",
      "11079    negative\n",
      "7617     negative\n",
      "11600    negative\n",
      "13014    negative\n",
      "8981     negative\n",
      "11654    negative\n",
      "464      positive\n",
      "12157    positive\n",
      "2140     negative\n",
      "Name: airline_sentiment, Length: 3660, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I will be using an SVM classifier to train and predict sentiment\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear', random_state = 0)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' ... 'negative' 'positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2109  166   52]\n",
      " [ 327  397   48]\n",
      " [ 136   72  353]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7811475409836065"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_test, y_pred)\n",
    "print(cm2)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we saw that our SVM performed with 78% accuracy, much better than how our first model performed. \n",
    "### I would like to see if using another approach, like logistic regression, will result in a better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\alexa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2  = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'negative', 'positive',\n",
       "       'negative'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2186  112   29]\n",
      " [ 383  340   49]\n",
      " [ 175   67  319]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7773224043715847"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm3 = confusion_matrix(y_test, y_pred2)\n",
    "print(cm3)\n",
    "accuracy_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using logistic regression we still did not beat the 78% accuracy of the SVM. I did notice that the logistic regression model did take a significantly shorter time in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I would like to attempt one more model, using the Naive Bayes approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier2 = GaussianNB()\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = classifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'positive', ..., 'negative', 'positive',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 726  595 1006]\n",
      " [  54  266  452]\n",
      " [  39   63  459]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39644808743169396"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm4 = confusion_matrix(y_test, y_pred3)\n",
    "print(cm4)\n",
    "accuracy_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearly the Naive Bayes model performed the worst out of all we have tried, with only around 40% accuracy. \n",
    "### The model that performed best was the SVM, with 78% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I will analyze my movie review dataset on sentiment analysis it using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8a6ac9bfff4b9b9152fec4c47b4811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't reach server at 'https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-finetuned-sst-2-english-modelcard.json' to download model card file.\n",
      "Creating an empty model card.\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9997898}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998695}]\n"
     ]
    }
   ],
   "source": [
    "#testing it out\n",
    "print(nlp('This is very bad'))\n",
    "print(nlp('This is great!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's once again download data and look at it\n",
    "df = pd.read_csv('Desktop\\Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I always wrote this series off as being a comp...      0\n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
       "2  This movie was so poorly written and directed ...      0\n",
       "3  The most interesting thing about Miryang (Secr...      1\n",
       "4  when i first read about \"berlin am meer\" i did...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I only want to look at the first 100\n",
    "df = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to add a new column which shows how the nlp will label the movie reviews\n",
    "df['nlp_label'] = df['text'].apply(lambda text: nlp(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to clean up the column of nlp_label so that it only shows the negative\n",
    "df['nlp_label'] = df['nlp_label'].apply(lambda label: 'pos' if 'POSITIVE' in str(label) else 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>nlp_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label nlp_label\n",
       "0  I always wrote this series off as being a comp...   neg       neg\n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...   neg       neg\n",
       "2  This movie was so poorly written and directed ...   neg       neg\n",
       "3  The most interesting thing about Miryang (Secr...   pos       pos\n",
       "4  when i first read about \"berlin am meer\" i did...   neg       neg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>nlp_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.77544266}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.95181304}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.99860674}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.99531436}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.9989304}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  I always wrote this series off as being a comp...   neg   \n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...   neg   \n",
       "2  This movie was so poorly written and directed ...   neg   \n",
       "3  The most interesting thing about Miryang (Secr...   pos   \n",
       "4  when i first read about \"berlin am meer\" i did...   neg   \n",
       "\n",
       "                                      nlp_label  \n",
       "0  [{'label': 'NEGATIVE', 'score': 0.77544266}]  \n",
       "1  [{'label': 'NEGATIVE', 'score': 0.95181304}]  \n",
       "2  [{'label': 'NEGATIVE', 'score': 0.99860674}]  \n",
       "3  [{'label': 'POSITIVE', 'score': 0.99531436}]  \n",
       "4   [{'label': 'NEGATIVE', 'score': 0.9989304}]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now I will replace all the 0's and 1's in the label column to either positive or negative\n",
    "df['label'] = df['label'].replace(1, 'pos')\n",
    "df['label'] = df['label'].replace(0, 'neg')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  2]\n",
      " [ 9 36]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now I will create confusion matrix to evaluate how it performed\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(df['label'], df['nlp_label'])\n",
    "print(cm)\n",
    "accuracy_score(df['label'], df['nlp_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With an 89% accuracy, clearly this performed the best out of all models, even with me encountering difficulties with it in the beginning of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
